{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from visualisation import visualise_features, visualise_dataset\n",
    "from utilities import load_dataframe, performance, cross_validation_feature_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel if needed\n",
    "# import os\n",
    "# os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "### Visualise our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our dataframe\n",
    "df = load_dataframe()\n",
    "visualise_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't tell us a huge amount. Let's split the volume directions up into separate dataframes and have a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two separate data frames, one for each junction\n",
    "df_north = df.drop(columns=[\"southBound\"])\n",
    "df_south = df.drop(columns=[\"northBound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataframe, let's look at a seasonality and trend plot. This could illuminate some more details to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base features performance, where we use K Nearest Neighbors.\n",
    "# Here is our baseline, now we add features.\n",
    "performance(df_north, \"northBound\")\n",
    "visualise_features([\"dayOfWeek\", \"month\", \"time\"], df_north, f\"Base Features - Northbound\", \"northBound\")\n",
    "\n",
    "performance(df_south, \"southBound\")\n",
    "visualise_features([\"dayOfWeek\", \"month\", \"time\"], df_south, f\"Base Features - Southbound\", \"southBound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see:\n",
    "1. A weekly seasonality\n",
    "2. A yearly seasonality\n",
    "3. No overall trend throughout the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_north[\"quarter\"] = df.index.quarter\n",
    "df_north[\"weekOfYear\"] = df.index.weekofyear\n",
    "df_north[\"dayOfYear\"] = df.index.dayofyear\n",
    "\n",
    "df_south[\"quarter\"] = df.index.quarter\n",
    "df_south[\"weekOfYear\"] = df.index.weekofyear\n",
    "df_south[\"dayOfYear\"] = df.index.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(df_north, \"northBound\")\n",
    "# visualise_features([\"quarter\", \"weekOfYear\", \"dayOfYear\"], df_north, \"Additional Features\", \"northBound\")\n",
    "\n",
    "\n",
    "performance(df_south, \"southBound\")\n",
    "# visualise_features([\"quarter\", \"weekOfYear\", \"dayOfYear\"], df_south, \"Additional Features\", \"southBound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some more date-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our dataframes back to original features by running cell towards top\n",
    "df_north = df.drop(columns=[\"southBound\"])\n",
    "df_south = df.drop(columns=[\"northBound\"])\n",
    "\n",
    "import pandas as pd\n",
    "ireland_holidays = {(1,1), (17,3), (5,4), (3,5), (7,6), (2,8), (25,10), (25,12), (26,12)}\n",
    "# Get our dataframes back to original features\n",
    "df_north = df.drop(columns=[\"southBound\"])\n",
    "df_south = df.drop(columns=[\"northBound\"])\n",
    "\n",
    "# Define a function to use in our mapping\n",
    "def f(x):\n",
    "    day = x.day\n",
    "    month = x.month\n",
    "    if((day,month) in ireland_holidays):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_north[\"weekday\"] = df.index.weekday\n",
    "series = pd.Series(df_north.index).apply(f)\n",
    "df_north[\"holiday\"] = series.to_list()\n",
    "df_north = df_north.fillna(0)\n",
    "\n",
    "df_south[\"weekday\"] = df.index.weekday\n",
    "series = pd.Series(df_south.index).apply(f)\n",
    "df_south[\"holiday\"] = series.to_list()\n",
    "df_south = df_south.fillna(0)\n",
    "\n",
    "\n",
    "# Check performance\n",
    "performance(df_north, \"northBound\")\n",
    "performance(df_south, \"southBound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review:\n",
    "Looks like our base features do best.\n",
    "Newer features perform quite poorly, though this could be because we have such a small dataset right now.#\n",
    "However, the dayOfYear plot demonstrates some pretty significant seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Create lagging features\n",
    "#### Need to encode components of time series data such as seasonality, trend and cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 20, 5\n",
    "fig = plot_acf(df_north[\"northBound\"], lags=168)\n",
    "\n",
    "plt.title(\"Autocorrelation of Traffic Volume for Northbound traffic (Through a week)\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Lag at k\")\n",
    "fig.show()\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 20, 5\n",
    "fig = plot_acf(df_north[\"northBound\"], lags=24)\n",
    "\n",
    "plt.title(\"Autocorrelation of Traffic Volume for Northbound traffic (Through a day)\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Lag at k\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_north.copy()\n",
    "cross_validation_feature_params(test_params=[1,3,5,7,24], df=temp, feature_type=\"lag\", target_var=\"northBound\")\n",
    "\n",
    "# Hour\n",
    "temp[\"volume_lag_1\"] = temp[\"northBound\"].shift(1, fill_value=0)\n",
    "performance(temp, \"northBound\")\n",
    "# Difference feature\n",
    "temp[\"volume_lag_1_diff\"] = temp[\"northBound\"] - temp[\"volume_lag_1\"]\n",
    "performance(temp, \"northBound\")\n",
    "# # Day\n",
    "# temp[\"volume_lag_24\"] = temp[\"northBound\"].shift(24, fill_value=0)\n",
    "# performance(temp, \"northBound\")\n",
    "# # Week\n",
    "# temp[\"volume_lag_week\"] = temp[\"northBound\"].shift(168, fill_value=0)\n",
    "# performance(temp, \"northBound\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a lag of 1, and a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_north = df.drop(columns=[\"southBound\"])\n",
    "df_south = df.drop(columns=[\"northBound\"])\n",
    "\n",
    "df_north = df.drop(columns=[\"southBound\"])\n",
    "df_north[\"volume_lag_1\"] = df_north[\"northBound\"].shift(1, fill_value=0)\n",
    "df_north[\"volume_lag_1_diff\"] = df_north[\"volume_lag_1\"] - df_north[\"northBound\"].shift(2, fill_value=0)\n",
    "performance(df_north, \"northBound\")\n",
    "\n",
    "df_south = df.drop(columns=[\"northBound\"])\n",
    "df_south[\"volume_lag_1\"] = df_south[\"southBound\"].shift(1, fill_value=0)\n",
    "df_south[\"volume_lag_1_diff\"] = df_north[\"volume_lag_1\"] - df_south[\"southBound\"].shift(2, fill_value=0)\n",
    "performance(df_south, \"southBound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvement when using a lag of 1. Anything higher results in pretty poor results, Let's try a Rolling Window Feature\n",
    "\n",
    "### Rolling Window Features\n",
    "For this, we'll try the mean, min, max, and sum in each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_north.copy()\n",
    "cross_validation_feature_params(test_params=[2,3,5,7,9,11,13,24], df=temp, feature_type=\"rolling_window_max\", target_var=\"northBound\")\n",
    "temp['window_max'] = temp['northBound'].rolling(window = 2).max()\n",
    "temp['window_max'] = temp['window_max'].fillna(0)\n",
    "performance(temp, \"northBound\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower error again with the rolling window. Try mean rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_a = df_north.copy()\n",
    "cross_validation_feature_params(test_params=[2,3,5,7,9,11,13], df=temp, feature_type=\"rolling_window_mean\", target_var=\"northBound\")\n",
    "temp['window_mean'] = temp['northBound'].rolling(window = 2).mean()\n",
    "temp['window_mean'] = temp['window_mean'].fillna(0)\n",
    "performance(temp, \"northBound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better again! See if min does any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_north.copy()\n",
    "cross_validation_feature_params(test_params=[2,3,5,7,9,11,13], df=temp, feature_type=\"rolling_window_min\", target_var=\"northBound\")\n",
    "temp['window_min'] = temp['northBound'].rolling(window = 2).min()\n",
    "temp['window_min'] = temp['window_min'].fillna(0)\n",
    "performance(temp, \"northBound\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite as good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the mean rolling window as a feature. These will be added once we've figured out how to use em for forecasting. They do a pretty nice job though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Northbound\n",
    "# df_north['window_mean'] = df_north['northBound'].rolling(window = 2).mean()\n",
    "# df_north['window_mean'] = df_north['window_mean'].fillna(0)\n",
    "# performance(df_north, \"northBound\")\n",
    "# # Southbound\n",
    "# df_south['window_mean'] = df_south['southBound'].rolling(window = 2).mean()\n",
    "# df_south['window_mean'] = df_south['window_mean'].fillna(0)\n",
    "# performance(df_south, \"southBound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see better performance as we dont have the cross validated features also in the dataframe. \n",
    "This performance is particularly good for such a basic model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We're going to try a few different models provided by sklearn. We could look beyond into things like Keras, ARIMA and XGBOOST, but I don't think it's necessary for this assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold out a validation set. This will be used later once we've narrowed down the params for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to hold out 12 hours of data points to predict on!~\n",
    "def train_test_split(X,y,test_size):\n",
    "\treturn (X[:-test_size, :], X[-test_size:, :], y[:-test_size], y[-test_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast size\n",
    "n_forecast = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable\n",
    "y_north = df_north[\"northBound\"].to_numpy()\n",
    "y_south = df_south[\"southBound\"].to_numpy()\n",
    "\n",
    "# Feature Vectors\n",
    "X_north = df_north.drop(columns=[\"northBound\"]).to_numpy()\n",
    "X_south = df_south.drop(columns=[\"southBound\"]).to_numpy()\n",
    "\n",
    "# Hold out a validation set\n",
    "(X_north, X_north_val, y_north, y_north_val) = train_test_split(X_north, y_north, test_size=n_forecast)\n",
    "(X_south, X_south_val, y_south, y_south_val) = train_test_split(X_south, y_south, test_size=n_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's look into Lasso and Ridge Regression first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import evaluate_lasso_hyperparams, evaluate_ridge_hyperparams\n",
    "evaluate_lasso_hyperparams(X_north,y_north, [3,50,100,200,300])\n",
    "evaluate_ridge_hyperparams(X_north,y_north, [0.000001,0.0001,0.1,10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty awful performance lol. Not really surprising though. What is surprising is how well kNN does..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import evaluate_decision_tree_hyperparams\n",
    "decision_tree_model=evaluate_decision_tree_hyperparams(X_north,y_north, [2,5,6,7,8,9,10,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Max Depth of 6 looks good here, lets validate using forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualisation import visualise_decision_tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from utilities import n_one_step_ahead_prediction\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from visualisation import visualise_forecast_vs_true\n",
    "\n",
    "\n",
    "decision_tree_model=DecisionTreeRegressor(max_depth=6).fit(X_north,y_north)\n",
    "\n",
    "y_forecast_north = n_one_step_ahead_prediction(decision_tree_model, X_north_val, n=n_forecast)\n",
    "print(\"MSE: \"+str(mean_squared_error(y_north_val, y_forecast_north)))\n",
    "x_axis = df.iloc[-n_forecast:].index.to_numpy()\n",
    "visualise_forecast_vs_true(x_axis,y_north_val,y_forecast_north,\"Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try build on our decision tree using AdaBoost\n",
    "Tuning parameters takes a while so I'll leave it commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "\n",
    "from models import evaluate_ada_boost_hyperparams\n",
    "evaluate_ada_boost_hyperparams(X_north,y_north) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ada_boost_model = AdaBoostRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(max_depth=7),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1,\n",
    "    loss='exponential').fit(X_north,y_north)\n",
    "\n",
    "y_forecast_north = n_one_step_ahead_prediction(ada_boost_model, X_north_val, n=n_forecast)\n",
    "print(\"MSE: \"+str(mean_squared_error(y_north_val, y_forecast_north)))\n",
    "x_axis = df.iloc[-n_forecast:].index.to_numpy()\n",
    "visualise_forecast_vs_true(x_axis,y_north_val,y_forecast_north,\"Ada Boost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Grid search to find the best combination of params for a random forest.\n",
    "With those best params, we then test the performance. Takes a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import evaluate_random_forest_hyperparams\n",
    "test_params = {\n",
    "\"n_estimators\": [20, 50, 60, 100],\n",
    "'max_features': ['auto', 'sqrt', 'log2'],\n",
    "'max_depth' : [i for i in range(5,20)]\n",
    "}\n",
    "evaluate_random_forest_hyperparams(X_north, y_north, test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a figure for the performance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "import numpy as np\n",
    "rf_model = RandomForestRegressor(n_estimators=60, max_features=\"auto\",max_depth=14)\n",
    "scores = cross_validate(\n",
    "        rf_model,\n",
    "        X_north,\n",
    "        y_north,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        return_estimator=True,\n",
    "    )\n",
    "\n",
    "base_mse = np.sqrt(-np.mean(scores[\"test_score\"]))\n",
    "print(f\"MSE is: {format(base_mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the best hyper params for an ANN. We'll plot the error bars for it since the slides do it. Takes about six minutes to run... Comment it out then run it once everything else is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import evaluate_MLP_hidden_nodes, evaluate_MLP_penalty_weight\n",
    "#evaluate_MLP_hidden_nodes(X_north,y_north, [5,10,15,30,50,100])\n",
    "#evaluate_MLP_penalty_weight(X_north,y_north, [0.1,1,10,100,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=60, max_features=\"auto\",max_depth=14).fit(X_north, y_north)\n",
    "y_forecast_north = n_one_step_ahead_prediction(rf_model, X_north_val, n=n_forecast)\n",
    "print(mean_squared_error(y_north_val, y_forecast_north))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise this\n",
    "visualise_forecast_vs_true(x_axis, y_north_val, y_forecast_north, model_name=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=100, alpha=1000,max_iter=500).fit(X_north, y_north)\n",
    "y_forecast_north = n_one_step_ahead_prediction(mlp_model, X_north_val, n=n_forecast)\n",
    "print(mean_squared_error(y_north_val, y_forecast_north))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_forecast_vs_true(x_axis, y_north_val, y_forecast_north, model_name=\"MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooff"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ea5f822aeab596314334ea1e62fe92926319a59f671f6f66e274027cdf6cea6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
